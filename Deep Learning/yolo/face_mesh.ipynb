{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"fm1.mp4\")\n",
    "\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces = 1)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "drawSpec = mpDraw.DrawingSpec(thickness = 1, circle_radius = 1)\n",
    "\n",
    "pTime = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = faceMesh.process(imgRGB)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_TESSELATION, drawSpec, drawSpec)\n",
    "    \n",
    "        for id, lm in enumerate(faceLms.landmark):\n",
    "            h, w, _ = img.shape\n",
    "            cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime - pTime)\n",
    "    pTime = cTime\n",
    "    cv2.putText(img, \"FPS: \"+str(int(fps)), (10,65), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)  \n",
    "    \n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Results will contain the face mesh landmarks\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmp_face_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Draw the face mesh on the frame\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_face_landmarks:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize drawing and face mesh tools\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(\"fm1.mp4\")  # Change 0 to your video file path if desired\n",
    "\n",
    "# Define drawing spec for better visualization\n",
    "drawing_spec = mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "style = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Results will contain the face mesh landmarks\n",
    "    results = mp_face_mesh(rgb_frame)\n",
    "\n",
    "    # Draw the face mesh on the frame\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=frame, landmark_list=face_landmarks, connections=mp_face_mesh.FACEMESH_TESSELLATION,\n",
    "                connection_drawing_spec=drawing_spec, landmark_drawing_spec=style\n",
    "            )\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Mesh', frame)\n",
    "\n",
    "    # Exit loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m webcam:success,img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[1;32m---> 20\u001b[0m imgContours , conts \u001b[38;5;241m=\u001b[39m \u001b[43mutlis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetContours\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminArea\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(conts) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m     biggest \u001b[38;5;241m=\u001b[39m conts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Yaramis\\Documents\\GitHub\\DataScience\\Deep Learning\\yolo\\utlis.py:7\u001b[0m, in \u001b[0;36mgetContours\u001b[1;34m(img, cThr, showCanny, minArea, filter, draw)\u001b[0m\n\u001b[0;32m      5\u001b[0m imgGray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      6\u001b[0m imgBlur \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(imgGray,(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m),\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m imgCanny \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCanny\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgBlur\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcThr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcThr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      9\u001b[0m imgDial \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdilate(imgCanny,kernel,iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import utlis\n",
    "\n",
    "###################################\n",
    "webcam = True\n",
    "path = '1.jpg'\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(10,160)\n",
    "cap.set(3,1920)\n",
    "cap.set(4,1080)\n",
    "scale = 3\n",
    "wP = 210 *scale\n",
    "hP= 297 *scale\n",
    "###################################\n",
    "\n",
    "while True:\n",
    "    if webcam:success,img = cap.read()\n",
    "    else: img = cv2.imread(path)\n",
    "\n",
    "    imgContours , conts = utlis.getContours(img,minArea=50000,filter=4)\n",
    "    if len(conts) != 0:\n",
    "        biggest = conts[0][2]\n",
    "        #print(biggest)\n",
    "        imgWarp = utlis.warpImg(img, biggest, wP,hP)\n",
    "        imgContours2, conts2 = utlis.getContours(imgWarp,\n",
    "                                                 minArea=2000, filter=4,\n",
    "                                                 cThr=[50,50],draw = False)\n",
    "        if len(conts) != 0:\n",
    "            for obj in conts2:\n",
    "                cv2.polylines(imgContours2,[obj[2]],True,(0,255,0),2)\n",
    "                nPoints = utlis.reorder(obj[2])\n",
    "                nW = round((utlis.findDis(nPoints[0][0]//scale,nPoints[1][0]//scale)/10),1)\n",
    "                nH = round((utlis.findDis(nPoints[0][0]//scale,nPoints[2][0]//scale)/10),1)\n",
    "                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[1][0][0], nPoints[1][0][1]),\n",
    "                                (255, 0, 255), 3, 8, 0, 0.05)\n",
    "                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[2][0][0], nPoints[2][0][1]),\n",
    "                                (255, 0, 255), 3, 8, 0, 0.05)\n",
    "                x, y, w, h = obj[3]\n",
    "                cv2.putText(imgContours2, '{}cm'.format(nW), (x + 30, y - 10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,\n",
    "                            (255, 0, 255), 2)\n",
    "                cv2.putText(imgContours2, '{}cm'.format(nH), (x - 70, y + h // 2), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,\n",
    "                            (255, 0, 255), 2)\n",
    "        cv2.imshow('A4', imgContours2)\n",
    "\n",
    "    img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "    cv2.imshow('Original',img)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
