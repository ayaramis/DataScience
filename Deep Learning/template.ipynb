{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Data**"
      ],
      "metadata": {
        "id": "jIObhy6_q4ZQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OPin82uq15z"
      },
      "outputs": [],
      "source": [
        "df0 = pd.read_csv(\"penguins_size.csv\")\n",
        "df = df0.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Insights**"
      ],
      "metadata": {
        "id": "qYX_7VIcrJPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s9Ekglsq153"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4BTnUR3q154"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxJkCsvEq154"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU4yqNWfq155"
      },
      "source": [
        "**Duplicate Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRuhbQjvq157"
      },
      "outputs": [],
      "source": [
        "# Veri setindeki yinelenen gözlemleri kontrol eder ve bunları kaldırır\n",
        "\n",
        "def duplicate_values(df):\n",
        "    print(\"Duplicate check...\")\n",
        "    num_duplicates = df.duplicated(subset=None, keep='first').sum()\n",
        "    if num_duplicates > 0:\n",
        "        print(\"There are\", num_duplicates, \"duplicated observations in the dataset.\")\n",
        "        df.drop_duplicates(keep='first', inplace=True)\n",
        "        print(num_duplicates, \"duplicates were dropped!\")\n",
        "        print(\"No more duplicate rows!\")\n",
        "    else:\n",
        "        print(\"There are no duplicated observations in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1y2xeH0q158"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated(keep=False)].sort_values(by=list(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Values**"
      ],
      "metadata": {
        "id": "tQwb1zASrX4X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxyHL_uJq159"
      },
      "outputs": [],
      "source": [
        "def missing_values(df):\n",
        "    missing_number = df.isnull().sum().sort_values(ascending = False)\n",
        "    missing_percent = (df.isnull().sum() / df.isnull().count()).sort_values(ascending = False)\n",
        "    missing_values = pd.concat([missing_number, missing_percent], axis = 1, keys = ['Missing_Number', 'Missing_Percent'])\n",
        "    return missing_values[missing_values['Missing_Number'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZd9olmYq15-"
      },
      "outputs": [],
      "source": [
        "# Veri setindeki tüm '?' değerlerini NaN ile değiştirir\n",
        "\n",
        "df.replace(to_replace='?',value=np.nan,inplace=True)\n",
        "\n",
        "#df=df.applymap(lambda x: np.nan if x=='?' else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE-s9VJ4q15_"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['occupation'] = df['occupation'].fillna(method='bfill')\n",
        "\n",
        "# bfill (backward fill), eksik değerleri bir sonraki mevcut değerle doldurur.\n",
        "# ffill (forward fill), eksik değerleri bir önceki mevcut değerle doldurur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFgsPv-6q16B"
      },
      "outputs": [],
      "source": [
        "df = df.dropna() #1\n",
        "df.drop(columns=[\"Car_Name\", \"Year\"], inplace=True) #2\n",
        "df.drop(index=[2614], inplace =True)#3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Variables**"
      ],
      "metadata": {
        "id": "Yeoc-bCTrsVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-_fiIbqq16B"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.select_dtypes(include =\"object\").head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNz1AGEkq16A"
      },
      "outputs": [],
      "source": [
        "df[\"Clicked on Ad\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Yv20gkq16A"
      },
      "outputs": [],
      "source": [
        "df[df.make_model==\"Audi A2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZTP-HA6q16A"
      },
      "outputs": [],
      "source": [
        "for col in df.select_dtypes('object'):\n",
        "    print(f\"{col:<20}:\", df[col].nunique())\n",
        "\n",
        "# <20 ile en soldan \":\" işaretine kadar 20 karakterlik boşluk bırakılır ve feature isimleri bu boşluğa yazdırılır.\n",
        "# \":\" işareti tüm satırlarda aynı hizaya getirilmiş olur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOsRAiymq16B"
      },
      "outputs": [],
      "source": [
        "for feature in df.columns:\n",
        "    if df[feature].dtype==\"object\":\n",
        "        print(feature, df[feature].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md67hLAuq15_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "ax = sns.countplot(y = df['occupation'], hue = df['income'])\n",
        "plt.title(\"Income by occupation\", fontsize = 16)\n",
        "ax.bar_label(ax.containers[0]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "112btKnjq16C"
      },
      "outputs": [],
      "source": [
        "df.Sex = df.Sex.replace({'female': 0, 'male': 1})\n",
        "df['income']=df['income'].map({'<=50K': 0, '>50K': 1})\n",
        "df['education'].replace(['11th', '9th', '7th-8th', '5th-6th', '10th', '1st-4th', '12th'], 'School', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa73rdsuq16C"
      },
      "outputs": [],
      "source": [
        "cat_features = df.select_dtypes(include='object').columns\n",
        "num_features = df.select_dtypes(include='number').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGDn8_Osq16C"
      },
      "outputs": [],
      "source": [
        "def unique_values(df, columns):\n",
        "    \"\"\"Prints unique values and their counts for specific columns in the DataFrame.\"\"\"\n",
        "\n",
        "    for column_name in columns:\n",
        "        print(f\"Column: {column_name}\\n{'-'*30}\")\n",
        "        unique_vals = df[column_name].unique()\n",
        "        value_counts = df[column_name].value_counts()\n",
        "        print(f\"Unique Values ({len(unique_vals)}): {unique_vals}\\n\")\n",
        "        print(f\"Value Counts:\\n{value_counts}\\n{'='*40}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P85ii_9Jq16D"
      },
      "outputs": [],
      "source": [
        "unique_values(df, cat_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ3xlJddq16D"
      },
      "outputs": [],
      "source": [
        "df[df.species ==\"Gentoo\"].groupby(\"sex\").describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZnHRXoEq16D"
      },
      "outputs": [],
      "source": [
        "df.loc[336, \"sex\"] = \"MALE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4r76y2hq16E"
      },
      "outputs": [],
      "source": [
        "# Kategorik feature ların dağılımını göstermek için;\n",
        "\n",
        "for column in cat_features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    ax = sns.countplot(x=column, data=df, palette='viridis')\n",
        "    plt.title(f'Distribution of Categories {column}')\n",
        "\n",
        "    # Barlar üzerindeki sayımları otomatik olarak etiketle\n",
        "    ax.bar_label(ax.containers[0])\n",
        "\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2thyYzwq16E"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df, hue = \"species\", palette = \"Dark2\", corner=True);\n",
        "sns.pairplot(df,hue=\"Clicked on Ad\", corner=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZAjUiVMq16E"
      },
      "outputs": [],
      "source": [
        "index = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "for feature in df.select_dtypes(\"number\"):\n",
        "    if feature != \"species\":\n",
        "        index += 1\n",
        "        plt.subplot(2,2,index)\n",
        "        sns.boxplot(x='species',y=feature,data=df)\n",
        "\n",
        "# pair plotdan aldığımız insight ları burdan da alabiliyoruz."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outliers**"
      ],
      "metadata": {
        "id": "pCXiLE-zsEKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oJibFN8q16F"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "sns.boxplot(x=\"make_model\", y=\"price\", data=df, whis=3)\n",
        "plt.show()\n",
        "\n",
        "# Aşağıdaki görsellere baktığımızda boxplota göre Audi A3, Opel Astra, Opel insignia, Renault clio için 3 wisker\n",
        "# baz alınarak outlier olabilecek gözlemleri görebiliyoruz. Kendi datalarınızda\n",
        "# bu görsellere göre her grup için ayrı wisker değerleri belirleyebilirsiniz.\n",
        "\n",
        "# IQR hesaplamak için şu adımlar izlenir:\n",
        "\n",
        "# Veriler küçükten büyüğe sıralanır.\n",
        "# Verilerin %25'ini ve %75'ini temsil eden ilk ve üçüncü çeyrekler hesaplanır.\n",
        "# IQR, üçüncü çeyrekten ilk çeyrek çıkarılarak elde edilir.\n",
        "\n",
        "# Q1 = df.groupby('make_model')['price'].quantile(0.25)\n",
        "# Q3 = df.groupby('make_model')['price'].quantile(0.75)\n",
        "# IQR = Q3-Q1\n",
        "# lower_lim = Q1-1.5*IQR\n",
        "# upper_lim = Q3+1.5*IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL0ird4Jq16F"
      },
      "outputs": [],
      "source": [
        "# Seaborn'un boxplot fonksiyonu tüm kategoriler için aynı 'whis' değerini kullanır, bu nedenle\n",
        "# her bir kategoriyi ayrı ayrı çizmek için matplotlib'in boxplot fonksiyonunu kullanacağız.\n",
        "\n",
        "whisker_values = {\n",
        "    'Audi A1': 2.0,\n",
        "    'Audi A3': 1.5,\n",
        "    'Opel Astra': 2.0,\n",
        "    'Opel Corsa': 2.5,\n",
        "    'Opel Insignia': 3.0,\n",
        "    'Renault Clio': 2.0,\n",
        "    'Renault Duster': 1.5,\n",
        "    'Renault Espace': 3.0\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "for i, make_model in enumerate(whisker_values.keys()):\n",
        "    model_data = df[df['make_model'] == make_model]['price']\n",
        "    plt.boxplot(model_data, positions=[i], whis=whisker_values[make_model], widths=0.5)\n",
        "\n",
        "plt.xticks(range(len(whisker_values)), whisker_values.keys())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2eAuaZaq16F"
      },
      "outputs": [],
      "source": [
        "# 1.5 wisker değerine göre her bir gruba ait outlier olabileceğini değerlendirdiğimiz gözlemleri tespit ediyoruz.\n",
        "\n",
        "total_outliers = []\n",
        "\n",
        "for model in df.make_model.unique():\n",
        "\n",
        "    car_prices = df[df[\"make_model\"]== model][\"price\"]\n",
        "\n",
        "    Q1 = car_prices.quantile(0.25)\n",
        "    Q3 = car_prices.quantile(0.75)\n",
        "    IQR = Q3-Q1\n",
        "    lower_lim = Q1-1.5*IQR\n",
        "    upper_lim = Q3+1.5*IQR\n",
        "\n",
        "    count_of_outliers = (car_prices[(car_prices < lower_lim) | (car_prices > upper_lim)]).count()\n",
        "\n",
        "    total_outliers.append(count_of_outliers)\n",
        "\n",
        "    print(f\" The count of outlier for {model:<15} : {count_of_outliers:<5}, \\\n",
        "          The rate of outliers : {(count_of_outliers/len(df[df['make_model']== model])).round(3)}\")\n",
        "print()\n",
        "print(\"Total_outliers : \",sum(total_outliers), \"The rate of total outliers :\", (sum(total_outliers)/len(df)).round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlations**"
      ],
      "metadata": {
        "id": "PmL6I8KrsJ4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLOc2HfUq16E"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.select_dtypes(\"number\").corr(),annot=True, cmap='viridis')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMPq_Yryq16F"
      },
      "outputs": [],
      "source": [
        "corr_by_price = df.corr()[\"price\"].sort_values()[:-1]\n",
        "corr_by_price\n",
        "\n",
        "# datamızdaki tüm featurların target ile olan corr.larına bakıyoruz\n",
        "# targetımız olan price ile corr.larını küçükten büyüğe sıralıyoruz.\n",
        "# Targetın kendisiyle olan corr.unu görmek istemediğimizden slicelama ([:-1]) yapıp -1 ile targetı ignore ediyoruz.\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "sns.barplot(x = corr_by_price.index, y = corr_by_price)\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout();\n",
        "\n",
        "# featureler ile target arasındaki corr.ları görselleştiriyoruz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4Fg1fPq16G"
      },
      "source": [
        "## Multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2fyUDxWq16G"
      },
      "outputs": [],
      "source": [
        "df_numeric.corr()[(df_numeric.corr()>= 0.9) & (df_numeric.corr() < 1)].any().any()\n",
        "\n",
        "# +0.9 ile +1 arasındaki corr. değerleri için multicollinearity kontrolünü bu kod ile yapabiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm-1oG15q16H"
      },
      "source": [
        "**Dependent independent Variable Assignment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2n42LKoq16H"
      },
      "outputs": [],
      "source": [
        "X= df.drop(columns=\"income\")\n",
        "y= df.income"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDfFqje2q16H"
      },
      "source": [
        "**Unbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjX-S7lRq16H"
      },
      "outputs": [],
      "source": [
        "# veri setim unbalanced olduğundan stratify=y kullanıyorum\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBws5S3tq16H"
      },
      "outputs": [],
      "source": [
        "cat_onehot = ['workclass', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'marital.status']\n",
        "cat_ordinal = ['education', 'capital_diff']\n",
        "\n",
        "cat_for_edu = ['Preschool', 'School', 'HS-grad','Some-college', 'Assoc-voc', 'Assoc-acdm','Bachelors', 'Masters', 'Prof-school', 'Doctorate']\n",
        "cat_for_capdiff = ['Low', 'High']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYA4V57Mq16N"
      },
      "outputs": [],
      "source": [
        "# train ve test setinin metriclerini karşılaştırabilmek için fonksiyonumuzu tanımlıyoruz.\n",
        "\n",
        "def train_val(model, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    scores = {\n",
        "    \"train\": {\n",
        "    \"R2\" : r2_score(y_train, y_train_pred),\n",
        "    \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
        "    \"mse\" : mean_squared_error(y_train, y_train_pred),\n",
        "    \"rmse\" : np.sqrt(mean_squared_error(y_train, y_train_pred))},\n",
        "\n",
        "    \"test\": {\n",
        "    \"R2\" : r2_score(y_test, y_pred),\n",
        "    \"mae\" : mean_absolute_error(y_test, y_pred),\n",
        "    \"mse\" : mean_squared_error(y_test, y_pred),\n",
        "    \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))}\n",
        "               }\n",
        "\n",
        "    return pd.DataFrame(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxVgusXPq16O"
      },
      "outputs": [],
      "source": [
        "def adj_r2(y_test, y_pred, df):\n",
        "    r2 = r2_score(y_test, y_pred)       # Modelin R2 değerini hesaplar\n",
        "    n = df.shape[0]                     # Veri setindeki gözlem (örnek) sayısını alır\n",
        "    p = df.shape[1]-1                   # Bağımsız değişkenlerin (feature ların) sayısını alır\n",
        "    adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)   # Adjusted R2 formülünü kullanarak değeri hesaplar\n",
        "    return adj_r2"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}